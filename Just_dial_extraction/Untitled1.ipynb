{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07649665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proxy Error: HTTPSConnectionPool(host='www.justdial.com', port=443): Max retries exceeded with url: /Pune/Computer-Dealers-in-Pimpri/nct-10110698/page-1 (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 400 Bad Request')))\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Define the proxy server address and port\n",
    "proxy = '139.177.147.13'\n",
    "\n",
    "# Define the URL you want to scrape\n",
    "url = 'https://www.justdial.com/Pune/Computer-Dealers-in-Pimpri/nct-10110698/page-1'\n",
    "\n",
    "# Set up proxy configuration\n",
    "proxies = {'http': proxy, 'https': proxy}\n",
    "\n",
    "try:\n",
    "    response = requests.get(url, proxies=proxies)\n",
    "    if response.status_code == 200:\n",
    "        # Process the response here\n",
    "        print(response.text)\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n",
    "\n",
    "except requests.exceptions.ProxyError as e:\n",
    "    print(f\"Proxy Error: {e}\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Request Exception: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc4affc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request Exception: HTTPSConnectionPool(host='www.justdial.com', port=443): Max retries exceeded with url: /Pune/Computer-Dealers-in-Pimpri/nct-10110698/page-1 (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1129)')))\n",
      "Request Exception: HTTPSConnectionPool(host='www.justdial.com', port=443): Max retries exceeded with url: /Pune/Computer-Dealers-in-Pimpri/nct-10110698/page-1 (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1129)')))\n",
      "Request Exception: HTTPSConnectionPool(host='www.justdial.com', port=443): Max retries exceeded with url: /Pune/Computer-Dealers-in-Pimpri/nct-10110698/page-1 (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1129)')))\n",
      "Failed to retrieve page 1\n",
      "Request Exception: HTTPSConnectionPool(host='www.justdial.com', port=443): Max retries exceeded with url: /Pune/Computer-Dealers-in-Pimpri/nct-10110698/page-2 (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1129)')))\n",
      "Request Exception: HTTPSConnectionPool(host='www.justdial.com', port=443): Max retries exceeded with url: /Pune/Computer-Dealers-in-Pimpri/nct-10110698/page-2 (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1129)')))\n",
      "Request Exception: HTTPSConnectionPool(host='www.justdial.com', port=443): Max retries exceeded with url: /Pune/Computer-Dealers-in-Pimpri/nct-10110698/page-2 (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1129)')))\n",
      "Failed to retrieve page 2\n",
      "Request Exception: HTTPSConnectionPool(host='www.justdial.com', port=443): Max retries exceeded with url: /Pune/Computer-Dealers-in-Pimpri/nct-10110698/page-3 (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1129)')))\n",
      "Request Exception: HTTPSConnectionPool(host='www.justdial.com', port=443): Max retries exceeded with url: /Pune/Computer-Dealers-in-Pimpri/nct-10110698/page-3 (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1129)')))\n",
      "Request Exception: HTTPSConnectionPool(host='www.justdial.com', port=443): Max retries exceeded with url: /Pune/Computer-Dealers-in-Pimpri/nct-10110698/page-3 (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1129)')))\n",
      "Failed to retrieve page 3\n",
      "Request Exception: HTTPSConnectionPool(host='www.justdial.com', port=443): Max retries exceeded with url: /Pune/Computer-Dealers-in-Pimpri/nct-10110698/page-4 (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1129)')))\n",
      "Request Exception: HTTPSConnectionPool(host='www.justdial.com', port=443): Max retries exceeded with url: /Pune/Computer-Dealers-in-Pimpri/nct-10110698/page-4 (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1129)')))\n",
      "Request Exception: HTTPSConnectionPool(host='www.justdial.com', port=443): Max retries exceeded with url: /Pune/Computer-Dealers-in-Pimpri/nct-10110698/page-4 (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1129)')))\n",
      "Failed to retrieve page 4\n",
      "Data saved to Pimpri_pune_computer_dealer.xlsx\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "\n",
    "# List of proxy servers\n",
    "proxies = [\n",
    "    'https://139.177.147.13'      #proxy = 'http://username:password@your-proxy-server.com:port'\n",
    "    \n",
    "    # Add more proxies here\n",
    "]\n",
    "\n",
    "# Initialize lists to store data\n",
    "name_list = []\n",
    "address_list = []\n",
    "contact_list = []\n",
    "\n",
    "# Function to make a request with retries and proxy rotation\n",
    "def make_request(url, headers, proxy):\n",
    "    retries = 3  # Number of retries before giving up\n",
    "    for _ in range(retries):\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, proxies=proxy)\n",
    "            if response.status_code == 200:\n",
    "                return response\n",
    "        except requests.exceptions.ProxyError as e:\n",
    "            print(f\"Proxy Error: {e}\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Request Exception: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "        # Sleep for a short time before retrying\n",
    "        time.sleep(random.uniform(1, 3))\n",
    "\n",
    "    return None\n",
    "\n",
    "# Loop through multiple pages\n",
    "for page in range(1, 5):  # Scraping up to 10 pages, adjust as needed\n",
    "    url = f'https://www.justdial.com/Pune/Computer-Dealers-in-Pimpri/nct-10110698/page-{page}'\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.5845.180 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    # Select a random proxy for each request\n",
    "    proxy = {'http': random.choice(proxies), 'https': random.choice(proxies)}\n",
    "\n",
    "    response = make_request(url, headers, proxy)\n",
    "\n",
    "    if response is not None:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        names = soup.find_all(['a', 'div', 'span'], class_={'jsx-3349e7cd87e12d75 resultbox_title_anchor line_clamp_1 font22 fw500 color111'})\n",
    "        address = soup.find_all('div', class_=[\"jsx-3349e7cd87e12d75 font15 fw400 color111\"])\n",
    "        contact = soup.find_all('span', class_='jsx-3349e7cd87e12d75 callcontent callNowAnchor')\n",
    "\n",
    "        # Check if all lists have the same length\n",
    "        if len(names) == len(address) == len(contact):\n",
    "            name_list.extend([name.text for name in names])\n",
    "            address_list.extend([add.text for add in address])\n",
    "            contact_list.extend([number.text for number in contact])\n",
    "        else:\n",
    "            print(f\"Lists on page {page} have different lengths.\")\n",
    "    else:\n",
    "        print(f\"Failed to retrieve page {page}\")\n",
    "\n",
    "    # Sleep for a random time (between 1 to 3 seconds) to avoid being detected as a bot\n",
    "    time.sleep(random.uniform(1, 3))\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "df = pd.DataFrame({'Names': name_list, 'Address': address_list, 'Contact Number': contact_list})\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df.to_excel('Proxy_Pimpri_pune_computer_dealer.xlsx', index=False)\n",
    "print(\"Data saved to Pimpri_pune_computer_dealer.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a1129dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred on page 1: HTTPSConnectionPool(host='www.justdial.com', port=443): Max retries exceeded with url: /Pune/Computer-Dealers-in-Pimpri/nct-10110698/page-1 (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 400 Bad Request')))\n",
      "An error occurred on page 2: HTTPSConnectionPool(host='www.justdial.com', port=443): Max retries exceeded with url: /Pune/Computer-Dealers-in-Pimpri/nct-10110698/page-2 (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 400 Bad Request')))\n",
      "An error occurred on page 3: HTTPSConnectionPool(host='www.justdial.com', port=443): Max retries exceeded with url: /Pune/Computer-Dealers-in-Pimpri/nct-10110698/page-3 (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 400 Bad Request')))\n",
      "An error occurred on page 4: HTTPSConnectionPool(host='www.justdial.com', port=443): Max retries exceeded with url: /Pune/Computer-Dealers-in-Pimpri/nct-10110698/page-4 (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 400 Bad Request')))\n",
      "Data saved to Pimpri_pune_computer_dealer.xlsx\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "\n",
    "# List of proxy servers\n",
    "proxies = [\n",
    "    '141.101.123.7',\n",
    "    '141.193.213.120',\n",
    "    # Add more proxies here\n",
    "]\n",
    "\n",
    "# Initialize lists to store data\n",
    "name_list = []\n",
    "address_list = []\n",
    "contact_list = []\n",
    "\n",
    "# Loop through multiple pages\n",
    "for page in range(1, 5):  # Scraping up to 10 pages, adjust as needed\n",
    "    url = f'https://www.justdial.com/Pune/Computer-Dealers-in-Pimpri/nct-10110698/page-{page}'\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.5845.180 Safari/537.36'}\n",
    "    \n",
    "    # Select a random proxy for each request\n",
    "    proxy = random.choice(proxies)\n",
    "    proxy_dict = {'http': proxy, 'https': proxy}\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, proxies=proxy_dict)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            names = soup.find_all(['a', 'div', 'span'], class_={'jsx-3349e7cd87e12d75 resultbox_title_anchor line_clamp_1 font22 fw500 color111'})\n",
    "            address = soup.find_all('div', class_=[\"jsx-3349e7cd87e12d75 font15 fw400 color111\"])\n",
    "            contact = soup.find_all('span', class_='jsx-3349e7cd87e12d75 callcontent callNowAnchor')\n",
    "\n",
    "            # Check if all lists have the same length\n",
    "            if len(names) == len(address) == len(contact):\n",
    "                name_list.extend([name.text for name in names])\n",
    "                address_list.extend([add.text for add in address])\n",
    "                contact_list.extend([number.text for number in contact])\n",
    "            else:\n",
    "                print(f\"Lists on page {page} have different lengths.\")\n",
    "        else:\n",
    "            print(f\"Failed to retrieve page {page}\")\n",
    "\n",
    "        # Sleep for a random time (between 1 to 5 seconds) to avoid being detected as a bot\n",
    "        time.sleep(random.uniform(1, 5))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred on page {page}: {str(e)}\")\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "df = pd.DataFrame({'Names': name_list, 'Address': address_list, 'Contact Number': contact_list})\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df.to_excel('Pimpri_pune_computer_dealer.xlsx', index=False)\n",
    "print(\"Data saved to Pimpri_pune_computer_dealer.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1973b693",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ad0a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize lists to store data\n",
    "name_list = []\n",
    "address_list = []\n",
    "contact_list = []\n",
    "\n",
    "# Loop through multiple pages\n",
    "for page in range(1, 100000):  # Scraping up to 10 pages, adjust as needed\n",
    "    url = f'https://www.justdial.com/Pune/Computer-Repair-Services/nct-10890482?filters=%5B%7B%22e%22%3A%22100%22%2C%22v%22%3A%5B%22Distance%22%5D%2C%22mh%22%3A%5B%22Sortby%22%5D%7D%5D/page-{page}'\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.5845.180 Safari/537.36'}\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        names = soup.find_all(['a', 'div', 'span'], class_={'jsx-3349e7cd87e12d75 resultbox_title_anchor line_clamp_1 font22 fw500 color111'})\n",
    "        address = soup.find_all('div', class_=[\"jsx-3349e7cd87e12d75 font15 fw400 color111\"])\n",
    "        contact = soup.find_all('span', class_='import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize lists to store data\n",
    "name_list = []\n",
    "address_list = []\n",
    "contact_list = []\n",
    "\n",
    "# Loop through multiple pages\n",
    "for page in range(1, 100000):  # Scraping up to 10 pages, adjust as needed\n",
    "    url = f'https://www.justdial.com/Pune/Computer-Repair-Services/nct-10890482/page-{page}'\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.5845.180 Safari/537.36'}\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        names = soup.find_all(['a', 'div', 'span'], class_={'jsx-3349e7cd87e12d75 resultbox_title_anchor line_clamp_1 font22 fw500 color111'})\n",
    "        address = soup.find_all('div', class_=[\"jsx-3349e7cd87e12d75 font15 fw400 color111\"])\n",
    "        contact = soup.find_all('span', class_='jsx-3349e7cd87e12d75 callcontent callNowAnchor')\n",
    "        \n",
    "\n",
    "        # Check if all lists have the same length\n",
    "        if len(names) == len(address) == len(contact):\n",
    "            name_list.extend([name.text for name in names])\n",
    "            address_list.extend([add.text for add in address])\n",
    "            contact_list.extend([number.text for number in contact])\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            print(f\"Lists on page {page} have different lengths.\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to retrieve page {page}\")\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "df = pd.DataFrame({'Names': name_list, 'Address': address_list, 'Contact Number': contact_list})\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df.to_excel('computer_shop.xlsx', index=False)\n",
    "print(\"Data saved to computer_repair_services.xlsx\")')\n",
    "        \n",
    "\n",
    "        # Check if all lists have the same length\n",
    "        if len(names) == len(address) == len(contact):\n",
    "            name_list.extend([name.text for name in names])\n",
    "            address_list.extend([add.text for add in address])\n",
    "            contact_list.extend([number.text for number in contact])\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            print(f\"Lists on page {page} have different lengths.\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to retrieve page {page}\")\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "df = pd.DataFrame({'Names': name_list, 'Address': address_list, 'Contact Number': contact_list})\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df.to_excel('computer_shop.xlsx', index=False)\n",
    "print(\"Data saved to computer_repair_services.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
